my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(data=1:20,nrow=4,ncol=5)
identical(my_matrix,my_matrix2)
patients <- c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients,my_matrix)
my_data
class(data_frame)
class(my_data)
cnames <- c("patient","age","weight","bp","rating","test")
colnames(my_data) <- cnames
my_data
TRUE==TRUE
(FALSE==TRUE)==FALSE
6==7
c<7
6<7
10<=10
5!=7
!(5==7)
!5==7
FALSE & FALSE
TRUE & c(TRUE,FALSE,FALSE)
TRUE && c(TRUE,FALSE,FALSE)
TRUE | c(TRUE,FALSE,FALSE)
TRUE !! c(TRUE,FALSE,FALSE)
TRUE || c(TRUE,FALSE,FALSE)
5>8 || 6!=8 && 4>3.9
isTRUE(6>4)
identical('twins','twins')
xor(5==6,!FALSE)
ints <- sample(10)
ints
ints>5
which(ints>7)
any(ints<0)
all(ints>0)
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
sapply(flags,class)
cls_vect<-sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors,sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes <- flags[,19:23]
lapply(flag_colors)
lapply(flag_colors,range)
lapply(flag_shapes,range)
shape_mat <- sapply(flag_shape,range)
shape_mat <- sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals<-lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(flags,unique)
lapply(unique_vals,function(elem) elem[2])
viewinfo()
sapply(flags,unique)
vapply(flags,unique,numeric(1))
ok()
sapply(flags,class)
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass,mean)
source('~/Desktop/JM/data_science_coursera/MODULE_2_R_PROGRAMMING/ASSIGNMENT_1/corr.R')
tapply(flags$population,flags$red,summary)
tapply(flags$population,flags$landmass,summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:5,4,replace=TRUE)
sample(1:6,4,replace=TRUE)
sample(1:6,4,replace=TRUE)
sample(1:20,10,replace=FALSE)
sample(1:20,10)
LETTERS
sample(LETTERS)
sflips<-ample(c(0,1),100,replace=TRUE,prob=c(0.3,0.7))
flips<-sample(c(0,1),100,replace=TRUE,prob=c(0.3,0.7))
flipts
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=0.7)
flips2 <- rbinom(100,size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100,sd=25)
?rpois
rpois(5,lambda=10)
my_pois<-replicate(100,rpois(5,10))
my_pois
cm<-colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
Sys.time()
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<=as.POSIXlt(Sys.time())
t2<-as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
source('~/Desktop/JM/data_science_coursera/MODULE_2_R_PROGRAMMING/ASSIGNMENT_1/corr.R')
source('~/Desktop/JM/data_science_coursera/MODULE_2_R_PROGRAMMING/ASSIGNMENT_1/complete.R')
swirl()
library(swirl)
ls()
rm(ls())
rm(list=ls())
swirl()
t3<-"October 17, 1986 08:24"
t4<-strptime(t3,"%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time()-t1
difftime(Sys.time(),t1,units='days')
?sample()
?sample
sample(1:6,4,replace=TRUE)
sample(1:6,4,replace=TRUE)
sample(1:20,10)
LETTERS
sample(LETTERS)
sample(c(0,1),100,replace=TRUE,prob=c(0.3,0.7))
flips<-sample(c(0,1),100,replace=TRUE,prob=c(0.3,0.7))
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=0.7)
flips2<-rbinom(100,size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100,sd=25)
rpois(5,10)
replicate(100,rpois(5,10))
my_pois<-replicate(100,rpois(5,10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
#install.packages('XML')
library(XML)
library(RCurl)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
xData <- getURL(fileURL)
doc <- xmlTreeParse(xData,useInternal=TRUE)
xmltop = xmlRoot(doc)
print(xmltop)[1:2,]
plantcat <- xmlSApply(xmltop, function(x) xmlSApply(x, xmlValue))
plantcat_df <- data.frame(t(plantcat),row.names=NULL)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
fileURL <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
doc
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml'
xData <- getURL(fileURL)
doc <- xmlTreeParse(xData,useInternal=TRUE)
xmltop = xmlRoot(doc)
install.packages('data.table')
library(data.table)
library(RCurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv ',"acs_idaho_2.csv", method = "curl")
DT <- fread('acs_idaho_2.csv')
sapply(split(DT$pwgtp15,DT$SEX),mean) #WORKS
mean(DT$pwgtp15,by=DT$SEX) # DOESN'T WORK
tapply(DT$pwgtp15,DT$SEX,mean) #WORKS
DT[,mean(pwgtp15),by=SEX] #WORKS
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) #WORKS
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] # DOESN'T WORK
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean)) #WORKS
system.time(tapply(DT$pwgtp15,DT$SEX,mean)) #WORKS
system.time(DT[,mean(pwgtp15),by=SEX]) #WORKS
system.time(mean(DT[DT$SEX==1,]$pwgtp15)) + system.time(mean(DT[DT$SEX==2,]$pwgtp15)) #WORKS
xpathSApply(xmlrootnode,"//zipcode",xmlValue)
xmlrootnode = xmlRoot(doc)
xpathSApply(xmlrootnode,"//zipcode",xmlValue)
sum(zipcode==21231)
sum(zipcodedata==21231)
zipcodedata <- xpathSApply(xmlrootnode,"//zipcode",xmlValue)
sum(zipcodedata==21231)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean)) #WORKS
system.time(tapply(DT$pwgtp15,DT$SEX,mean)) #WORKS
system.time(DT[,mean(pwgtp15),by=SEX]) #WORKS
system.time(mean(DT[DT$SEX==1,]$pwgtp15)) + system.time(mean(DT[DT$SEX==2,]$pwgtp15)) #WORKS
?unlist
?complete
install.packages('sqldf')
library(sqldf)
library(RCurl)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
library(sqldf)
library(RCurl)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
download.file(fileURL,"acs.csv", method = "curl")
sqldf("select pwgtp1 from acs where AGEP < 50")
acs <- fread('acs.csv')
library(data.table)
acs <- fread('acs.csv')
sqldf("select pwgtp1 from acs where AGEP < 50")
option1 <- sqldf("select * from acs where AGEP < 50")
option2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
option3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
option4 <- sqldf("select pwgtp1 from acs")
sum(option1 - option2)
sum(option1 - option3)
option1
option1 - option3
option1
all(option1==option3)
identical(option1,option3)
match_val <- unique(acs$AGEP)
match_val
match_guess1 <- sqldf("select unique AGEP from acs")
match_guess1 <- sqldf("select distinct AGEP from acs")
identical(match_val,match_guess1)
match_val
match_guess1
match_guess2 <- sqldf("select unique * from acs")
match_guess2 <- sqldf("select AGEP where unique from acs")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "72593c4c558532486564")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages(httpuv)
install.packages('httpuv')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github", "72593c4c558532486564")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
curl -i https://api.github.com/users/octocat/orgs
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github", "72593c4c558532486564")
myapp <- oauth_app("72593c4c558532486564", "d6543140f60718761145f749961b82f93e3782f0")
?oauth_app
myapp <- oauth_app("github",72593c4c558532486564", "d6543140f60718761145f749961b82f93e3782f0")
myapp <- oauth_app("github", "72593c4c558532486564", "d6543140f60718761145f749961b82f93e3782f0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
stop_for_status(req)
content(req)
all_git_data <- content(req)
all_git_data[1]
all_git_data$name
all_git_data[[name]]
all_git_data[name]
all_git_data$name
all_git_data[1]$name
all_git_data[1]
all_git_data[1][1]
all_git_data[1][1]$name
all_git_data[[1]]
all_git_data[1]
all_git_data[1][1]
all_git_data[1][1][1]
all_git_data[1][1][1][1]
all_git_data[1][1][1][1][1]
all_git_data[1][1][1][1][1][1]
class(all_git_data)
fix(all_git_data)
req
class(req)
req[1]
req[2]
req$name
json = jsonnlite::fromJSON(toJSON(all_git_data))
json = jsonlite::fromJSON(toJSON(all_git_data))
?toJSON
json <- jsonlite::fromJSON(toJSON(all_git_data))
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos.json"))
#stop_for_status(req)
all_git_data <- content(req)
json <- jsonlite::fromJSON(toJSON(all_git_data))
json <- jsonlite::fromJSON(toJSON(all_git_data))
library(jsonlite)
json <- jsonlite::fromJSON(toJSON(all_git_data))
json_data <- jsonlite::fromJSON(toJSON(all_git_data))
json_data
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
#stop_for_status(req)
all_git_data <- content(req)
json_data <- jsonlite::fromJSON(toJSON(all_git_data))
json_data
json_data$name
json_data[json_data$name=='datasharing']
json_data$name=='datasharing'
index = json_data$name=='datasharing'==TRUE
index = (json_data$name=='datasharing')==TRUE
index
index = (json_data$name=='datasharing')
index
json_data[5]
json_data
json_data[1,]
index = (json_data$name=='datasharing')
json_data[index,]
json_data[index,]$created_at
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readlines(con)
close(con)
htmlCode = readLines(con)
library(RCurl)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
class(htmlCode)
htmlCode[10]
nchar(htmlCode[10])
?sapply
sapply(c(10,20,30,100), function(x) {nchar(htmlCode[x]})
sapply(c(10,20,30,100), function(x) {nchar(htmlCode[x])})
library(RCurl)
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for'
download.file(fileURL,"prob5.csv", method = "curl")
file5 <- read.csv('prob5.csv')
View(file5)
View(file5)
?read.fwf
fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for'
download.file(fileURL,"prob5.for", method = "curl")
file5 <- read.fwf(file='prob5.for',widths=c(9,4,4,4,4,4,4,4,4),skip=3,header=TRUE)
file5 <- read.fwf(file='prob5.for',widths=c(9,4,4,4,4,4,4,4,4),skip=4,header=FALSE)
file5
file5 <- read.fwf(file='prob5.for',widths=c(10,4,4,4,4,4,4,4,4),skip=4,header=FALSE)
file5
file5 <- read.fwf(file='prob5.for',widths=c(10,10,10,10,10,10,10,10,10),skip=4,header=FALSE)
file5
file5[1:10,]
file5 <- read.fwf(file='prob5.for',widths=c(10,10,4,10,4,10,4,10,4),skip=4,header=FALSE)
file5[1:10,]
file5 <- read.fwf(file='prob5.for',widths=c(10,9,4,9,4,9,4,9,4),skip=4,header=FALSE)
file5[1:10,]
file5 <- read.fwf(file='prob5.for',widths=c(10,9,4,9,4,9,4,9,4),skip=3,header=TRUE)
file5 <- read.fwf(file='prob5.for',widths=c(10,9,4,9,4,9,4,9,4),skip=4,header=FALSE)
V1
file5$V1
sapply(c(10,20,30,100), function(x) {nchar(htmlCode[x])})
sum(file5$v4)
file5$v4
file5
file5[1:10,]
sum(file5$V4)
setwd("~/Desktop/JM/data_science_coursera/MODULE_3_GETTINGANDCLEANINGDATA/QUIZZES/QUIZ3")
library(Rcurl)
library(Curl)
library(curl)
library(rcurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv')
library(RCurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv','acs.csv',method="curl")
idaho_data <- read.csv('acs.csv')
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf','codebook.pdf',method="curl")
head(idaho_data)
?which
idaho_data$ACR
agricultureLogical <- (idaho_data$ACR==3 & idaho_data$AGS==6)
which(agricultureLogical)
agricultureLogical
install.packages('jpeg')
library(jpeg)
jpeg_file <- readJPEG('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg',native=TRUE)
library(RCurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg',question2.jpg,method="curl")
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg','question2.jpg',method="curl")
jpeg_file <- readJPEG('question2.jpg',native=TRUE)
jpeg_file
class(jpeg_file)
jpeg_file[1,1]
jpeg_file[1,2]
jpeg_file[1,3]
jpeg_file[1,]
jpeg[,1]
jpeg_file[,1]
?percentile
?quantile
quantile(jpef_file,.3)
quantile(jpeg_file,.3)
quantile(jpeg_file,c(.3,0.8))
library(RCurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv',gdp_data.csv,method='curl')
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv','gdp_data.csv',method='curl')
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv','educ_data.csv',method='curl')
gdp <- read.csv('gdp_data.csv')
educ <- read.csv('educ_data.csv')
head(gdp)
head(educ)
?read.csv
gdp_all <- read.csv('gdp_data.csv')
gdp <- gdp_all[6:195,c(1,2,4,5)]
gdp
?merge
gdp <- gdp_all[5:194,c(1,2,4,5)]
gdp
class(gdp)
class(educ)
head(gdp)
head(educ)
merged_data <- merge(gdp,educ,by=c('X.2','Short.Name'))
gdp$X.2
educ_data$Short.Name
educ$Short.Name
educ$Short.Name[1]
class(gdp)
class(educ)
merged_data <- merge(gdp,educ,by=c('X.2','Short.Name'))
merged_data <- merge(gdp,educ,by.x='X.2',by.y='Short.Name')
merged_data
gdp
educ
gdp
merged_data <- merge(gdp,educ,by.x='X.2',by.y='Table.Name')
merged_data
merged_data <- merge(gdp,educ,by.x='X.2',by.y='Table.Name')
nrows(merged_data)
n.rows(merged_data)
nrow(merged_data)
?sort
gdp
sorted_data <- merged_data[order(X.3)]
merged_data$X.3
sorted_data <- merged_data[order(merged_data$X.3)]
sorted_data <- merged_data[order(merged_data$X.3),]
sorted_data
sorted_data$Short.Name[13,]
sorted_data$Short.Name[13]
sorted_data <- merged_data[order(-merged_data$X.3),]
sorted_data$Short.Name[13]
sorted_data
sorted_data <- merged_data[order(merged_data$X.3),]
sorted_data
gdp
sorted_data <- merged_data[order(merged_data$Gross.domestic.product.2012),]
sorted_data
sorted_data <- merged_data[order(-merged_data$Gross.domestic.product.2012),]
sorted_data
?order
sorted_data <- merged_data[order(merged_data$Gross.domestic.product.2012,decreasing=TRUE),]
sorted_data
sorted_data$Short.Name[13]
setwd("~/Desktop/JM/data_science_coursera/MODULE_3_GETTINGANDCLEANINGDATA/PROJECT")
install.packages("RCurl")
library(RCurl)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip','all_data.zip',method='curl')
